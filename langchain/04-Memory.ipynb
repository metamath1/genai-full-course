{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpRBV9cJQLu3oMigLOJsWr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"dsMJyItoxcXx"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYz1CoA7xYFm","executionInfo":{"status":"ok","timestamp":1704628578463,"user_tz":-540,"elapsed":14047,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"71f702fb-de3b-41a2-bf70-b7f22a445b67"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip -q install openai\n","!pip -q install langchain"]},{"cell_type":"code","source":["!python -c \"import openai; print('openai:', openai.__version__)\"\n","!python -c \"import langchain; print('langchain:', langchain.__version__)\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsojl23yxlAG","executionInfo":{"status":"ok","timestamp":1704628612734,"user_tz":-540,"elapsed":1054,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"5edc7af9-b169-4c9c-f2c8-1b4176c4f7c8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["openai: 1.6.1\n","langchain: 0.1.0\n"]}]},{"cell_type":"code","source":["#API KEY 저장을 위한 os 라이브러리 호출\n","import os\n","from google.colab import userdata\n","\n","#OPENAI API키 저장\n","#API KEY 발급 페이지: https://platform.openai.com/docs/guides/gpt/completions-api\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"L3Q6I5sUx_iO","executionInfo":{"status":"ok","timestamp":1704628629877,"user_tz":-540,"elapsed":1598,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Chatting without Memory\n","\n","- langchain이 제공하는 chat model이라도 대화 내역을 자동으로 저장하지는 않음(stateless)"],"metadata":{"id":"h-0A1lHw18Uq"}},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI"],"metadata":{"id":"k6raJXfS2CT8","executionInfo":{"status":"ok","timestamp":1704629645777,"user_tz":-540,"elapsed":268,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["chatgpt = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n","chatgpt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmDWSgtZ2Dkr","executionInfo":{"status":"ok","timestamp":1704629670032,"user_tz":-540,"elapsed":277,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"a488036f-24cb-4a3d-98ad-6e8f9b3b1a19"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n","  warn_deprecated(\n"]},{"output_type":"execute_result","data":{"text/plain":["ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f657f25e770>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f657f2125c0>, model_name='gpt-3.5-turbo-1106', openai_api_key='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', openai_proxy='')"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["response = chatgpt.invoke(\"안녕! 나는 준우라고 해.\")\n","response.content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"dzlQcP4T2Dht","executionInfo":{"status":"ok","timestamp":1704629712425,"user_tz":-540,"elapsed":2025,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"416d6edb-ca85-4732-b38c-957da0f39e5f"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'안녕, 준우! 만나서 반가워. 무엇을 도와드릴까?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["response = chatgpt.invoke(\"1+1은 몇이야?\")\n","response.content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"DGTfMbj52DZ-","executionInfo":{"status":"ok","timestamp":1704629731397,"user_tz":-540,"elapsed":1337,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"87538d3c-e289-4dd6-fa93-c37ef7cdbdf0"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1+1은 2야.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["response = chatgpt.invoke(\"내 이름이 뭐였더라?\")\n","response.content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Bl6KBcjo2Yiz","executionInfo":{"status":"ok","timestamp":1704629759077,"user_tz":-540,"elapsed":2105,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"86b084a0-897f-41f1-a338-bd6a57717616"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'죄송합니다, 저는 귀하의 이름을 알 수 없습니다. 부르시겠어요?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["# Memory\n","\n","- 대화를 이어가기 위해서는 지난 대화 목록을 기억하고 있어야 함\n","\n","- OpenAI api를 사용하는 경우 다음처럼 messages를 구성해서 대화 목록을 유지\n","```python\n","response = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=[\n","      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","      {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n","      {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n","      {\"role\": \"user\", \"content\": \"Where was it played?\"}\n","    ]\n",")\n","```\n","\n","- 이렇게 직접 대화 목록을 유지하는 대신 자동으로 대화 목록을 유지하는 인터페이스를 langchain에서 제공\n","    - ConversationBufferMemory\n","    - ConversationBufferWindowMemory\n","    - ConversationTokenBufferMemory\n","    - ConversationSummaryMemory"],"metadata":{"id":"gcMxcHIM1IVn"}},{"cell_type":"markdown","source":["## ConversationBufferMemory\n","\n","- 지나간 대화 전체를 자동으로 저장하는 기능 제공"],"metadata":{"id":"WaGB0NWk14Nv"}},{"cell_type":"code","source":["from langchain_community.chat_models import ChatOpenAI\n","\n","from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory"],"metadata":{"id":"CIOGrVwCxssL","executionInfo":{"status":"ok","timestamp":1704628952513,"user_tz":-540,"elapsed":275,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo-1106')\n","\n","memory = ConversationBufferMemory()\n","\n","conversation = ConversationChain(\n","    llm=llm,\n","    memory=memory,\n","    verbose=True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zC9YoMZ7xtXz","executionInfo":{"status":"ok","timestamp":1704629254957,"user_tz":-540,"elapsed":296,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"09e9fe9b-fee0-40f2-83f6-21332a316d5f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n","  warn_deprecated(\n"]}]},{"cell_type":"code","source":["response = conversation.invoke(\"안녕! 나는 준우라고 해.\")\n","response['response']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"z7LS1RSAxuhn","executionInfo":{"status":"ok","timestamp":1704629256939,"user_tz":-540,"elapsed":1570,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"364e5d9d-fd46-4912-db65-ae9aa81d17fa"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: 안녕! 나는 준우라고 해.\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'안녕하세요, 준우님! 만나서 반가워요. 저는 OpenAI의 언어모델 GPT-3입니다. 어떻게 도와드릴까요?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["response = conversation.invoke(\"1+1은 몇이야?\")\n","response['response']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301},"id":"rW2gtgyizvuq","executionInfo":{"status":"ok","timestamp":1704629273938,"user_tz":-540,"elapsed":939,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"ed8c482f-a4f4-4495-e6f7-2bc16b667084"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: 안녕! 나는 준우라고 해.\n","AI: 안녕하세요, 준우님! 만나서 반가워요. 저는 OpenAI의 언어모델 GPT-3입니다. 어떻게 도와드릴까요?\n","Human: 1+1은 몇이야?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'2입니다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["response = conversation.invoke(\"내 이름이 뭐였더라?\")\n","response['response']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"b0IImbBQ0G1D","executionInfo":{"status":"ok","timestamp":1704629277846,"user_tz":-540,"elapsed":682,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"53af76b1-a877-49c1-e001-f8386b4527a5"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: 안녕! 나는 준우라고 해.\n","AI: 안녕하세요, 준우님! 만나서 반가워요. 저는 OpenAI의 언어모델 GPT-3입니다. 어떻게 도와드릴까요?\n","Human: 1+1은 몇이야?\n","AI: 2입니다.\n","Human: 내 이름이 뭐였더라?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'준우님이세요.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# https://api.python.langchain.com/en/latest/_modules/langchain/memory/buffer.html#\n","# 여기 소스를 보면 {}를 받기는 하는데 사용하지는 않음\n","\n","type(memory.load_memory_variables({}))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcolbWnf23pE","executionInfo":{"status":"ok","timestamp":1704630372114,"user_tz":-540,"elapsed":3,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"037a938f-ef83-4aa0-fd30-c475d3998b41"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["{'history': 'Human: 안녕! 나는 준우라고 해.\\nAI: 안녕하세요, 준우님! 만나서 반가워요. 저는 OpenAI의 언어모델 GPT-3입니다. 어떻게 도와드릴까요?\\nHuman: 1+1은 몇이야?\\nAI: 2입니다.\\nHuman: 내 이름이 뭐였더라?\\nAI: 준우님이세요.\\nHuman: 내 이름이 뭐였더라?\\nAI: 준우님이세요.'}\n"]},{"output_type":"execute_result","data":{"text/plain":["dict"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["- 메모리는 inputs, outputs이 쌍으로 저장된 일종의 사전"],"metadata":{"id":"3Vgqx0Vk49Ls"}},{"cell_type":"code","source":["memory = ConversationBufferMemory()"],"metadata":{"id":"_KGameJy25Xc","executionInfo":{"status":"ok","timestamp":1704631796237,"user_tz":-540,"elapsed":290,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["memory.save_context(inputs = {\"input\": \"안녕.\"}, outputs = {\"output\": \"무슨 일이시죠?\"})"],"metadata":{"id":"pcU2wm1e5Gpo","executionInfo":{"status":"ok","timestamp":1704631796704,"user_tz":-540,"elapsed":3,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["print(memory.load_memory_variables({}))"],"metadata":{"id":"R-tAcPzH_nD6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["memory.save_context({\"input\": \"별건 없고 그냥..\"}, {\"output\": \"무엇을 도와드릴까요?\"})"],"metadata":{"id":"MYTSPSNw5J6f","executionInfo":{"status":"ok","timestamp":1704631798298,"user_tz":-540,"elapsed":1,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["print(memory.load_memory_variables({}))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YI5YCq7F5bec","executionInfo":{"status":"ok","timestamp":1704631799205,"user_tz":-540,"elapsed":2,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"c6a4404e-d1ab-4cab-a385-afe27b046670"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: 안녕.\n","AI: 무슨 일이시죠?\n","Human: 별건 없고 그냥..\n","AI: 무엇을 도와드릴까요?\n"]}]},{"cell_type":"markdown","source":["## ConversationBufferWindowMemory\n","\n","- 모든 대화를 기억하면 context가 점점 길어져 토큰 제한을 넘길 수 있음\n","\n","- 토큰 제한 문제가 없어도 대화가 지속될 수록 비용이 증가\n","\n","- 모든 대화를 기억하지 않고 턴 기준으로 몇 턴을 저장할지 지정해서 사용하는 메모리"],"metadata":{"id":"AjBa8Ynw5gcq"}},{"cell_type":"code","source":["from langchain.memory import ConversationBufferWindowMemory"],"metadata":{"id":"TvnPurJ35cew","executionInfo":{"status":"ok","timestamp":1704630894600,"user_tz":-540,"elapsed":2,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# k=1 한턴의 대화만 기억한다.\n","memory = ConversationBufferWindowMemory(k=1)"],"metadata":{"id":"eM4tuhwc6z0X","executionInfo":{"status":"ok","timestamp":1704631818425,"user_tz":-540,"elapsed":466,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["# 메모리에 두 턴의 대화를 기록\n","memory.save_context(inputs = {\"input\": \"안녕.\"}, outputs = {\"output\": \"무슨 일이시죠?\"})\n","memory.save_context({\"input\": \"별건 없고 그냥..\"}, {\"output\": \"무엇을 도와드릴까요?\"})\n"],"metadata":{"id":"1qUzqawH61Ta","executionInfo":{"status":"ok","timestamp":1704631818918,"user_tz":-540,"elapsed":4,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["# 메모리 버퍼에는 최근 한 턴만 기록됨\n","print(memory.load_memory_variables({}))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fh5NGE-64Kj","executionInfo":{"status":"ok","timestamp":1704631818918,"user_tz":-540,"elapsed":3,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"5e03c756-c706-49d2-efeb-1bbe3a2ef81a"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: 별건 없고 그냥..\n","AI: 무엇을 도와드릴까요?\n"]}]},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo-1106')\n","\n","memory = ConversationBufferWindowMemory(k=1)\n","\n","conversation = ConversationChain(\n","    llm=llm,\n","    memory = memory,\n","    verbose=False # True로 바꾸고 상황을 확인해보기\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQ3IoZ_Z69Bo","executionInfo":{"status":"ok","timestamp":1704631825010,"user_tz":-540,"elapsed":291,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"12e41335-9fff-49e6-82b0-a797f2554519"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n","  warn_deprecated(\n"]}]},{"cell_type":"code","source":["response = conversation.invoke(\"안녕! 나는 준우라고 해.\")\n","response['response']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Ow9NpJ-W7Yk8","executionInfo":{"status":"ok","timestamp":1704631828064,"user_tz":-540,"elapsed":1748,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"6a37a077-b2b9-4063-cbb2-3928222834a6"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'안녕하세요, 준우님! 만나서 반가워요. 저는 OpenAI의 언어 모델 GPT-3입니다. 어떻게 도와드릴까요?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["response = conversation.invoke(\"1+1은 몇이야?\")\n","response['response']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"OL_23Pti7cqJ","executionInfo":{"status":"ok","timestamp":1704631828447,"user_tz":-540,"elapsed":386,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"8d86825f-211a-4bd4-ce06-f33612d0174c"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2입니다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["response = conversation.invoke(\"내 이름이 뭐였더라?\")\n","response['response']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"CkUYHKu87fbx","executionInfo":{"status":"ok","timestamp":1704631829550,"user_tz":-540,"elapsed":1105,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"3797764c-0f05-4733-fe4a-4bb777bfa72f"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'죄송합니다, 제가 당신의 이름을 알 수 없습니다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hfrts_vt7hN9","executionInfo":{"status":"ok","timestamp":1704631829551,"user_tz":-540,"elapsed":3,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"623e268c-54f0-47ef-ada2-d8b2f131d95c"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: 내 이름이 뭐였더라?\\nAI: 죄송합니다, 제가 당신의 이름을 알 수 없습니다.'}"]},"metadata":{},"execution_count":98}]},{"cell_type":"markdown","source":["## ConversationTokenBufferMemory\n","\n","- 대화 턴을 기준으로 저장하지 않고 허용 토큰 길이를 지정해서 대화 내용을 저장\n","\n","- 모델마다 토큰 세는 방식이 다르기 때문에 메모리를 생성할때 사용할 언어모델을 지정해야 함"],"metadata":{"id":"7QW8zkEz7nWi"}},{"cell_type":"code","source":["from langchain.memory import ConversationTokenBufferMemory"],"metadata":{"id":"MGX-sbi07kBr","executionInfo":{"status":"ok","timestamp":1704631835795,"user_tz":-540,"elapsed":287,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["# 토크나이징이 필요하기 때문에 OpenAI모델이 사용하는 토크나이저 설치\n","!pip -q install tiktoken"],"metadata":{"id":"JHlmwcWg7_pO","executionInfo":{"status":"ok","timestamp":1704631844399,"user_tz":-540,"elapsed":8160,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["# 메모리에 llm을 지정해야 하는데... 모델마다 토큰 세는 방식이 다르기 때문\n","# 이전 메모리 타입에서는 llm을 지정하지 않았음\n","memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=100)\n","\n","# max_token_limit 숫자가 커지면 많이 저장 작아지면 적게 저장(토큰 수준에서)\n","# 숫자 바꾸면서 상황을 확인하기\n","memory.save_context({\"input\": \"AI is what?!\"}, {\"output\": \"Amazing!\"})\n","memory.save_context({\"input\": \"Backpropagation is what?\"}, {\"output\": \"Beautiful!\"})\n","memory.save_context({\"input\": \"Chatbots are what?\"}, {\"output\": \"Charming!\"})"],"metadata":{"id":"2TOyBTs571-J","executionInfo":{"status":"ok","timestamp":1704631844399,"user_tz":-540,"elapsed":7,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BWzGMhm7-Na","executionInfo":{"status":"ok","timestamp":1704631844400,"user_tz":-540,"elapsed":8,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"bacdf981-300d-479a-db0d-328b56cb91ec"},"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: AI is what?!\\nAI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"]},"metadata":{},"execution_count":102}]},{"cell_type":"markdown","source":["## ConversationSummaryMemory\n","\n","- 대화 내용을 언어모델을 이용하여 요약한 후 요약 정보를 저장\n","\n","- 토큰 길이가 허용되면 요약하지 않고 그대로 저장"],"metadata":{"id":"Y271ox9u8UXi"}},{"cell_type":"code","source":["from langchain.memory import ConversationSummaryBufferMemory"],"metadata":{"id":"Ql1iwHq48KZa","executionInfo":{"status":"ok","timestamp":1704631336204,"user_tz":-540,"elapsed":5,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["# create a long string\n","schedule = \"\"\"오전 8시에 제품 팀과의 회의가 있습니다.\n","파워포인트 프레젠테이션을 준비해야 합니다.\n","오전 9시부터 오후 12시까지는 랭체인 프로젝트를 작업할 시간이 있는데, 랭체인은 매우 강력한 도구이기 때문에 빠르게 진행될 것입니다.\n","정오에는 한 시간 이상 떨어진 곳에서 차를 타고 온 고객과 함께 이탈리안 레스토랑에서 점심을 먹으며 최신 AI에 대한 이해를 돕습니다.\n","최신 LLM 데모를 보여드리기 위해 노트북을 꼭 가져가세요.\"\"\"\n","\n","# 400 토큰이면 요약하지 않음\n","memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100) # 80토큰으로 줄이고 마지막 대화가 요약되는지 확인\n","memory.save_context(inputs = {\"input\": \"안녕.\"}, outputs = {\"output\": \"무슨 일이시죠?\"})\n","memory.save_context({\"input\": \"별건 없고 그냥..\"}, {\"output\": \"무엇을 도와드릴까요?\"})\n","memory.save_context({\"input\": \"아..오늘 스케쥴이 어떻게 되지?\"},\n","                    {\"output\": f\"{schedule}\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNsgg03A8fnn","executionInfo":{"status":"ok","timestamp":1704631984014,"user_tz":-540,"elapsed":2146,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"8050dbb9-3a15-4d99-e7b8-d4a67d092038"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]}]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbftpA398yPe","executionInfo":{"status":"ok","timestamp":1704631984014,"user_tz":-540,"elapsed":6,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"0acd0ebd-bb97-4cf4-89c6-3e10f76ad936"},"execution_count":109,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'System: The human greets the AI in Korean and asks about their schedule. The AI responds with a detailed schedule including a morning meeting with the product team, working on the LangChain project, and having lunch with a client to discuss the latest AI advancements. The AI also reminds the human to bring their laptop for a latest LLM demo.'}"]},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["conversation = ConversationChain(\n","    llm=llm,\n","    memory = memory,\n","    verbose=True\n",")"],"metadata":{"id":"JqrSOdhk839k","executionInfo":{"status":"ok","timestamp":1704631984014,"user_tz":-540,"elapsed":5,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"무슨 데모를 보여주면 좋을까?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"id":"lxl8HFoP-qiO","executionInfo":{"status":"ok","timestamp":1704631989722,"user_tz":-540,"elapsed":5712,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"8c7a8046-28b4-465e-80a6-4ce70b074ee7"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","System: The human greets the AI in Korean and asks about their schedule. The AI responds with a detailed schedule including a morning meeting with the product team, working on the LangChain project, and having lunch with a client to discuss the latest AI advancements. The AI also reminds the human to bring their laptop for a latest LLM demo.\n","Human: 무슨 데모를 보여주면 좋을까?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"output_type":"execute_result","data":{"text/plain":["'저는 최신 LLM (Language Model) 데모를 보여주려고 합니다. 이 데모는 우리가 개발 중인 언어 모델의 최신 기능과 성능을 보여줄 것입니다. 이 모델은 언어 이해 및 생성 작업에 사용될 수 있으며, 실제 대화와 텍스트 생성에 활용될 수 있습니다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":111}]},{"cell_type":"code","source":["# 최대 토큰 100개를 맞추기위해 요약하는 부분과 요약 안하는 부분을 100 토큰 내에서 최적화해서 배치\n","# 토큰 수를 줄이고 대화가 어떻게 요약되는제 확인\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sEbiyMQZ-vV-","executionInfo":{"status":"ok","timestamp":1704631998229,"user_tz":-540,"elapsed":293,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"be00be51-765e-4d96-dd6e-9cd307475160"},"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"System: The human greets the AI in Korean and asks about their schedule. The AI responds with a detailed schedule including a morning meeting with the product team, working on the LangChain project, and having lunch with a client to discuss the latest AI advancements. The AI also reminds the human to bring their laptop for a latest LLM demo. The human asks what demo would be good to show, and the AI explains that they plan to showcase the latest LLM (Language Model) demo, which will demonstrate the model's advanced features and performance for language understanding and generation tasks, as well as its potential for real conversation and text generation.\"}"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":[],"metadata":{"id":"cTdBptY8-062"},"execution_count":null,"outputs":[]}]}