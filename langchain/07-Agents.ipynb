{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMzO0IwTtqhTNBgvocunJ2+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LangChain: Agents\n","\n","## Outline:\n","\n","* Using built in LangChain tools: Math and Wikipedia\n","* Defining your own tools"],"metadata":{"id":"89MvWX5iWWiJ"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"7jkhEP4JWet5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7p6xi4EQWJWZ"},"outputs":[],"source":["!pip -q install openai\n","!pip -q install langchain\n","!pip -q install langchain_openai # >= 0.1.0\n","\n","# !pip -q install docarray"]},{"cell_type":"code","source":["!pip install langchain_experimental\n","!pip install langchainhub"],"metadata":{"id":"JbLU4TW2XNlD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python -c \"import openai; print('openai:', openai.__version__)\"\n","!python -c \"import langchain; print('langchain:', langchain.__version__)\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYLP3vALWg_O","executionInfo":{"status":"ok","timestamp":1704950716514,"user_tz":-540,"elapsed":2036,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"16f82d31-3f9d-46b6-acd2-e98d041e327b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["openai: 1.7.1\n","langchain: 0.1.0\n"]}]},{"cell_type":"code","source":["#API KEY 저장을 위한 os 라이브러리 호출\n","import os\n","from google.colab import userdata\n","\n","#OPENAI API키 저장\n","#API KEY 발급 페이지: https://platform.openai.com/docs/guides/gpt/completions-api\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"qcok2nSeWirD","executionInfo":{"status":"ok","timestamp":1704950723365,"user_tz":-540,"elapsed":1351,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import langchain\n","\n","from langchain.agents import load_tools, initialize_agent\n","from langchain.agents import AgentType, AgentExecutor, create_react_agent, create_structured_chat_agent\n","\n","# old version\n","# from langchain.agents.agent_toolkits import create_python_agent\n","# from langchain.tools.python.tool import PythonREPLTool\n","from langchain_experimental.agents.agent_toolkits import create_python_agent\n","from langchain_experimental.tools.python.tool import PythonREPLTool\n","from langchain.python import PythonREPL\n","\n","from langchain_openai import ChatOpenAI, OpenAI # >= 0.1.0\n","# from langchain.chat_models import ChatOpenAI # for < 0.1.0"],"metadata":{"id":"VD_nMiPNWkcj","executionInfo":{"status":"ok","timestamp":1704958713151,"user_tz":-540,"elapsed":4,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":193,"outputs":[]},{"cell_type":"markdown","source":["# Built-in LangChain Tools\n","\n","- `llm-math`, `wikipedia`"],"metadata":{"id":"btvqTt88mYHa"}},{"cell_type":"code","source":["llm_model = \"gpt-3.5-turbo-1106\"\n","\n","llm = ChatOpenAI(temperature=0, model=llm_model)"],"metadata":{"id":"CeKPgOu_Woao","executionInfo":{"status":"ok","timestamp":1704959183043,"user_tz":-540,"elapsed":446,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":217,"outputs":[]},{"cell_type":"markdown","source":["## Setup Tools"],"metadata":{"id":"ny1DWcnzmmRy"}},{"cell_type":"code","source":["!pip install wikipedia"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-X8qj-1Xu3Y","executionInfo":{"status":"ok","timestamp":1704955307124,"user_tz":-540,"elapsed":8259,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"bdb50644-7fce-4895-dbd4-e94b56997440"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wikipedia\n","  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.11.17)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=ab5bc1141be7302a6f589914252a9ce8a51c8976a54c4a355a47b371eb81c9e4\n","  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"]}]},{"cell_type":"code","source":["tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"],"metadata":{"id":"mSwX1pJKXnQb","executionInfo":{"status":"ok","timestamp":1704958977622,"user_tz":-540,"elapsed":3,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":205,"outputs":[]},{"cell_type":"code","source":["agent = initialize_agent(\n","    tools=tools,\n","    llm=llm,\n","    # REACT 프레임워크를 따르는 제로샷으로 동작하는 에이전트\n","    # 즉 질문에 대한 [질의,응답] 예제없이 Thought, Action, Obervation, ... 을 반복하는 에이전트\n","    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n","    # 에이전트가 루프를 돌다가 에러가 나면 에러 메지지를 다시 llm에게 넣고\n","    # 적절히 에러를 수정하게 하는 옵션\n","    handle_parsing_errors=True,\n","    verbose = True)"],"metadata":{"id":"i3PvdkJPiNBc","executionInfo":{"status":"ok","timestamp":1704958982261,"user_tz":-540,"elapsed":519,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":206,"outputs":[]},{"cell_type":"markdown","source":["#### [참고] handle_parsing_errors 옵션 확인"],"metadata":{"id":"fGD9a41wiqGK"}},{"cell_type":"code","source":["from langchain import hub"],"metadata":{"id":"MK-_X6iFeCtb","executionInfo":{"status":"ok","timestamp":1704958996418,"user_tz":-540,"elapsed":482,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":207,"outputs":[]},{"cell_type":"code","source":["prompt = hub.pull(\"hwchase17/react\")\n","prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTJV6ZTVeDo1","executionInfo":{"status":"ok","timestamp":1704958997783,"user_tz":-540,"elapsed":865,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"a97a3ef8-c3ed-4d27-ef1c-84e2fbd25e36"},"execution_count":208,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"]},"metadata":{},"execution_count":208}]},{"cell_type":"code","source":["prompt.input_variables\n","# https://www.pinecone.io/learn/series/langchain/langchain-agents/\n","# agent_scratchpad 에 대한 설명있음\n","# 과거 Thought와 Action의 결과를 모두 지정하는 변수"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V93maTupfJIO","executionInfo":{"status":"ok","timestamp":1704959001079,"user_tz":-540,"elapsed":3,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"af0b8080-7279-4387-c7d9-08c5b38a2ec6"},"execution_count":209,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['agent_scratchpad', 'input', 'tool_names', 'tools']"]},"metadata":{},"execution_count":209}]},{"cell_type":"code","source":["print(prompt.template)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsP2U2AxeDj_","executionInfo":{"status":"ok","timestamp":1704959001506,"user_tz":-540,"elapsed":2,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"16824a72-f913-48b8-eb89-7cb5b425c60b"},"execution_count":210,"outputs":[{"output_type":"stream","name":"stdout","text":["Answer the following questions as best you can. You have access to the following tools:\n","\n","{tools}\n","\n","Use the following format:\n","\n","Question: the input question you must answer\n","Thought: you should always think about what to do\n","Action: the action to take, should be one of [{tool_names}]\n","Action Input: the input to the action\n","Observation: the result of the action\n","... (this Thought/Action/Action Input/Observation can repeat N times)\n","Thought: I now know the final answer\n","Final Answer: the final answer to the original input question\n","\n","Begin!\n","\n","Question: {input}\n","Thought:{agent_scratchpad}\n"]}]},{"cell_type":"code","source":["gpt_inst = OpenAI(temperature=0)\n","\n","# REACT 에이전트 생성\n","agent = create_react_agent(gpt_inst, tools, prompt)\n","agent_executor = AgentExecutor(\n","    agent=agent, tools=tools,\n","    # True로 하면 Action이 없으면 Action이 없다는 메세지를 다시 LLM에 다시 넣고\n","    # Thought를 기반으로 Action을 찾아냄\n","    handle_parsing_errors=True,\n","    verbose=True\n",")\n","\n","agent_executor.invoke(\n","    #  프롬프트에 Action: Wikipedia가 있으면 첫번째 체인에서 Action이 출력되지 않는 문제가 있음\n","    {\"input\": \"What is Leo DiCaprio's middle name?\\n\\nAction: Wikipedia\"}\n",")\n","\n","# ValueError: An output parsing error occurred.\n","# In order to pass this error back to the agent and have it try again,\n","# pass `handle_parsing_errors=True` to the AgentExecutor.\n","# This is the error: Could not parse LLM output: ` I should search for \"Leo DiCaprio\" on Wikipedia\n","# Action Input: Leo DiCaprio`"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wDHWlwWeDhi","executionInfo":{"status":"ok","timestamp":1704959040436,"user_tz":-540,"elapsed":5972,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"ae11b088-8bf6-41b3-a046-7e8c0df136a3"},"execution_count":213,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m I should use Wikipedia to search for information about Leo DiCaprio\n","Action Input: Leo DiCaprio\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mI should use Wikipedia to search for information about Leo DiCaprio\n","Action: Wikipedia\n","Action Input: Leo DiCaprio\u001b[0m\u001b[33;1m\u001b[1;3mPage: Leonardo DiCaprio\n","Summary: Leonardo Wilhelm DiCaprio (; Italian: [diˈkaːprjo]; born November 11, 1974) is an American actor and film producer. Known for his work in biographical and period films, he is the recipient of numerous accolades, including an Academy Award, a British Academy Film Award, and three Golden Globe Awards. As of 2019, his films have grossed over $7.2 billion worldwide, and he has been placed eight times in annual rankings of the world's highest-paid actors.\n","Born in Los Angeles, DiCaprio began his career in the late 1980s by appearing in television commercials. In the early 1990s, he had recurring roles in various television shows, such as the sitcom Parenthood, and had his first major film part as author Tobias Wolff in This Boy's Life (1993). He received critical acclaim and his first Academy Award and Golden Globe Award nominations for his performance as a developmentally disabled boy in What's Eating Gilbert Grape (1993). DiCaprio achieved international stardom with the star-crossed romances Romeo + Juliet (1996) and Titanic (1997). After the latter became the highest-grossing film in the world at the time, he reduced his workload for a few years. In an attempt to shed his image of a romantic hero, DiCaprio sought roles in other genres, including the 2002 crime dramas Catch Me If You Can and Gangs of New York; the latter marked the first of his many successful collaborations with director Martin Scorsese.\n","DiCaprio continued to gain acclaim for his performances in the biopic The Aviator (2004), the political thriller Blood Diamond (2006), the crime drama The Departed (2006) and the romantic drama Revolutionary Road (2008). He later made environmental documentaries and starred in several high-profile directors' successful projects, including the action thriller Inception (2010), the western Django Unchained (2012), the biopic The Wolf of Wall Street (2013), the survival drama The Revenant (2015)—for which he won the Academy Award for Best Actor— the comedy-dramas Once Upon a Time in Hollywood (2019) and Don't Look Up (2021), and the crime drama Killers of the Flower Moon (2023).\n","DiCaprio is the founder of Appian Way Productions—a production company that has made some of his films and the documentary series Greensburg (2008–2010)—and the Leonardo DiCaprio Foundation, a nonprofit organization devoted to promoting environmental awareness. A United Nations Messenger of Peace, he regularly supports charitable causes. In 2005, he was named a Commander of the Ordre des Arts et des Lettres for his contributions to the arts, and in 2016, he appeared in Time magazine's 100 most influential people in the world. DiCaprio was voted one of the 50 greatest actors of all time in a 2022 readers' poll by Empire.\n","\n","Page: George DiCaprio\n","Summary: George Paul DiCaprio (born October 2, 1943) is an American writer, editor, publisher, distributor, and former performance artist, known for his work in the realm of underground comix. DiCaprio has collaborated with Timothy Leary and Laurie Anderson. He is the father of actor Leonardo DiCaprio.\n","\n","Page: Shutter Island (film)\n","Summary: Shutter Island is a 2010 American neo-noir psychological thriller film directed by Martin Scorsese and adapted by Laeta Kalogridis, based on the 2003 novel of the same name by Dennis Lehane. Leonardo DiCaprio stars as Deputy U.S. Marshal Edward \"Teddy\" Daniels, who is investigating a psychiatric facility on Shutter Island after one of the patients goes missing. Mark Ruffalo plays his partner and fellow deputy marshal, Ben Kingsley plays the facility's lead psychiatrist, Max von Sydow plays a German doctor, and Michelle Williams plays Daniels' wife.\n","Released on February 19, 2010, Shutter Island received generally positive reviews from critics, was chosen by the National Board of Review as one of the top ten films of 2010, and grossed $295 million worldwide. The film is noted for its soundtrack, which prominently used classical music, such as that of Gus\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n","Final Answer: George\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': \"What is Leo DiCaprio's middle name?\\n\\nAction: Wikipedia\",\n"," 'output': 'George'}"]},"metadata":{},"execution_count":213}]},{"cell_type":"markdown","source":["## llm-math"],"metadata":{"id":"ITtgRenQmtsn"}},{"cell_type":"code","source":["# deprecated\n","# agent= initialize_agent(\n","#     tools=tools,\n","#     llm=llm,\n","#     agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n","#     handle_parsing_errors=True,\n","#     verbose = True)\n","\n","agent = create_react_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(\n","    agent=agent, tools=tools,\n","    handle_parsing_errors=True,\n","    verbose=True\n",")"],"metadata":{"id":"8UYL56DdXsA6","executionInfo":{"status":"ok","timestamp":1704959067952,"user_tz":-540,"elapsed":521,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":214,"outputs":[]},{"cell_type":"code","source":["agent_executor.invoke({\"input\":\"What is the 25% of 300?\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vr2SSbAKjsUp","executionInfo":{"status":"ok","timestamp":1704959074193,"user_tz":-540,"elapsed":6243,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"4ab14d0c-0a47-4ba1-ddc9-2d2f2b07d1b0"},"execution_count":215,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI need to calculate 25% of 300.\n","Action: Calculator\n","Action Input: 300 * 0.25\u001b[0m\u001b[36;1m\u001b[1;3mAnswer: 75.0\u001b[0m\u001b[32;1m\u001b[1;3mThe final answer is 75.0\n","Final Answer: 75.0\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'What is the 25% of 300?', 'output': '75.0'}"]},"metadata":{},"execution_count":215}]},{"cell_type":"code","source":["langchain.debug=True\n","agent_executor.invoke({\"input\":\"What is the 25% of 300?\"})\n","langchain.debug=False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8f39tpw1kXa4","executionInfo":{"status":"ok","timestamp":1704959195538,"user_tz":-540,"elapsed":7404,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"6af48fcd-ed90-479d-aa93-41b8d1ea22cd"},"execution_count":218,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"What is the 25% of 300?\"\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"What is the 25% of 300?\",\n","  \"intermediate_steps\": []\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"What is the 25% of 300?\",\n","  \"intermediate_steps\": []\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"What is the 25% of 300?\",\n","  \"intermediate_steps\": []\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:RunnableLambda] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"What is the 25% of 300?\",\n","  \"intermediate_steps\": []\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad> > 5:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n","\u001b[0m{\n","  \"output\": \"\"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad> > 4:chain:RunnableParallel<agent_scratchpad>] [9ms] Exiting Chain run with output:\n","\u001b[0m{\n","  \"agent_scratchpad\": \"\"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 3:chain:RunnableAssign<agent_scratchpad>] [11ms] Exiting Chain run with output:\n","\u001b[0m{\n","  \"input\": \"What is the 25% of 300?\",\n","  \"intermediate_steps\": [],\n","  \"agent_scratchpad\": \"\"\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:PromptTemplate] Entering Prompt run with input:\n","\u001b[0m{\n","  \"input\": \"What is the 25% of 300?\",\n","  \"intermediate_steps\": [],\n","  \"agent_scratchpad\": \"\"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 6:prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n","\u001b[0m{\n","  \"lc\": 1,\n","  \"type\": \"constructor\",\n","  \"id\": [\n","    \"langchain\",\n","    \"prompts\",\n","    \"base\",\n","    \"StringPromptValue\"\n","  ],\n","  \"kwargs\": {\n","    \"text\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Calculator, Wikipedia]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: What is the 25% of 300?\\nThought:\"\n","  }\n","}\n","\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] Entering LLM run with input:\n","\u001b[0m{\n","  \"prompts\": [\n","    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Calculator, Wikipedia]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: What is the 25% of 300?\\nThought:\"\n","  ]\n","}\n","\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 7:llm:ChatOpenAI] [2.33s] Exiting LLM run with output:\n","\u001b[0m{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \"I need to calculate 25% of 300.\\nAction: Calculator\\nAction Input: 25% * 300\",\n","        \"generation_info\": {\n","          \"finish_reason\": \"stop\",\n","          \"logprobs\": null\n","        },\n","        \"type\": \"ChatGeneration\",\n","        \"message\": {\n","          \"lc\": 1,\n","          \"type\": \"constructor\",\n","          \"id\": [\n","            \"langchain\",\n","            \"schema\",\n","            \"messages\",\n","            \"AIMessage\"\n","          ],\n","          \"kwargs\": {\n","            \"content\": \"I need to calculate 25% of 300.\\nAction: Calculator\\nAction Input: 25% * 300\",\n","            \"additional_kwargs\": {}\n","          }\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": {\n","    \"token_usage\": {\n","      \"completion_tokens\": 24,\n","      \"prompt_tokens\": 190,\n","      \"total_tokens\": 214\n","    },\n","    \"model_name\": \"gpt-3.5-turbo-1106\",\n","    \"system_fingerprint\": \"fp_cbe4fa03fe\"\n","  },\n","  \"run\": null\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:ReActSingleInputOutputParser] Entering Parser run with input:\n","\u001b[0m[inputs]\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence > 8:parser:ReActSingleInputOutputParser] [1ms] Exiting Parser run with output:\n","\u001b[0m{\n","  \"lc\": 1,\n","  \"type\": \"constructor\",\n","  \"id\": [\n","    \"langchain\",\n","    \"schema\",\n","    \"agent\",\n","    \"AgentAction\"\n","  ],\n","  \"kwargs\": {\n","    \"tool\": \"Calculator\",\n","    \"tool_input\": \"25% * 300\",\n","    \"log\": \"I need to calculate 25% of 300.\\nAction: Calculator\\nAction Input: 25% * 300\"\n","  }\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:RunnableSequence] [2.35s] Exiting Chain run with output:\n","\u001b[0m[outputs]\n","\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:Calculator] Entering Tool run with input:\n","\u001b[0m\"25% * 300\"\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:Calculator > 10:chain:LLMMathChain] Entering Chain run with input:\n","\u001b[0m{\n","  \"question\": \"25% * 300\"\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:Calculator > 10:chain:LLMMathChain > 11:chain:LLMChain] Entering Chain run with input:\n","\u001b[0m{\n","  \"question\": \"25% * 300\",\n","  \"stop\": [\n","    \"```output\"\n","  ]\n","}\n","\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:Calculator > 10:chain:LLMMathChain > 11:chain:LLMChain > 12:llm:ChatOpenAI] Entering LLM run with input:\n","\u001b[0m{\n","  \"prompts\": [\n","    \"Human: Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${Question with math problem.}\\n```text\\n${single line mathematical expression that solves the problem}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${Output of running the code}\\n```\\nAnswer: ${Answer}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\\\"37593 * 67\\\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\\\"37593**(1/5)\\\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: 25% * 300\"\n","  ]\n","}\n","\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:Calculator > 10:chain:LLMMathChain > 11:chain:LLMChain > 12:llm:ChatOpenAI] [2.37s] Exiting LLM run with output:\n","\u001b[0m{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \"```text\\n25/100 * 300\\n```\\n...numexpr.evaluate(\\\"25/100 * 300\\\")...\\n\",\n","        \"generation_info\": {\n","          \"finish_reason\": \"stop\",\n","          \"logprobs\": null\n","        },\n","        \"type\": \"ChatGeneration\",\n","        \"message\": {\n","          \"lc\": 1,\n","          \"type\": \"constructor\",\n","          \"id\": [\n","            \"langchain\",\n","            \"schema\",\n","            \"messages\",\n","            \"AIMessage\"\n","          ],\n","          \"kwargs\": {\n","            \"content\": \"```text\\n25/100 * 300\\n```\\n...numexpr.evaluate(\\\"25/100 * 300\\\")...\\n\",\n","            \"additional_kwargs\": {}\n","          }\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": {\n","    \"token_usage\": {\n","      \"completion_tokens\": 25,\n","      \"prompt_tokens\": 205,\n","      \"total_tokens\": 230\n","    },\n","    \"model_name\": \"gpt-3.5-turbo-1106\",\n","    \"system_fingerprint\": \"fp_cbe4fa03fe\"\n","  },\n","  \"run\": null\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:Calculator > 10:chain:LLMMathChain > 11:chain:LLMChain] [2.37s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"text\": \"```text\\n25/100 * 300\\n```\\n...numexpr.evaluate(\\\"25/100 * 300\\\")...\\n\"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:Calculator > 10:chain:LLMMathChain] [2.37s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"answer\": \"Answer: 75.0\"\n","}\n","\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 9:tool:Calculator] [2.38s] Exiting Tool run with output:\n","\u001b[0m\"Answer: 75.0\"\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence] Entering Chain run with input:\n","\u001b[0m[inputs]\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n","\u001b[0m[inputs]\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad> > 15:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n","\u001b[0m[inputs]\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad> > 15:chain:RunnableParallel<agent_scratchpad> > 16:chain:RunnableLambda] Entering Chain run with input:\n","\u001b[0m[inputs]\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad> > 15:chain:RunnableParallel<agent_scratchpad> > 16:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n","\u001b[0m{\n","  \"output\": \"I need to calculate 25% of 300.\\nAction: Calculator\\nAction Input: 25% * 300\\nObservation: Answer: 75.0\\nThought: \"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad> > 15:chain:RunnableParallel<agent_scratchpad>] [4ms] Exiting Chain run with output:\n","\u001b[0m{\n","  \"agent_scratchpad\": \"I need to calculate 25% of 300.\\nAction: Calculator\\nAction Input: 25% * 300\\nObservation: Answer: 75.0\\nThought: \"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad>] [6ms] Exiting Chain run with output:\n","\u001b[0m{\n","  \"input\": \"What is the 25% of 300?\",\n","  \"intermediate_steps\": [\n","    [\n","      {\n","        \"lc\": 1,\n","        \"type\": \"constructor\",\n","        \"id\": [\n","          \"langchain\",\n","          \"schema\",\n","          \"agent\",\n","          \"AgentAction\"\n","        ],\n","        \"kwargs\": {\n","          \"tool\": \"Calculator\",\n","          \"tool_input\": \"25% * 300\",\n","          \"log\": \"I need to calculate 25% of 300.\\nAction: Calculator\\nAction Input: 25% * 300\"\n","        }\n","      },\n","      \"Answer: 75.0\"\n","    ]\n","  ],\n","  \"agent_scratchpad\": \"I need to calculate 25% of 300.\\nAction: Calculator\\nAction Input: 25% * 300\\nObservation: Answer: 75.0\\nThought: \"\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 17:prompt:PromptTemplate] Entering Prompt run with input:\n","\u001b[0m[inputs]\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 17:prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n","\u001b[0m{\n","  \"lc\": 1,\n","  \"type\": \"constructor\",\n","  \"id\": [\n","    \"langchain\",\n","    \"prompts\",\n","    \"base\",\n","    \"StringPromptValue\"\n","  ],\n","  \"kwargs\": {\n","    \"text\": \"Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Calculator, Wikipedia]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: What is the 25% of 300?\\nThought:I need to calculate 25% of 300.\\nAction: Calculator\\nAction Input: 25% * 300\\nObservation: Answer: 75.0\\nThought: \"\n","  }\n","}\n","\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 18:llm:ChatOpenAI] Entering LLM run with input:\n","\u001b[0m{\n","  \"prompts\": [\n","    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Calculator, Wikipedia]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: What is the 25% of 300?\\nThought:I need to calculate 25% of 300.\\nAction: Calculator\\nAction Input: 25% * 300\\nObservation: Answer: 75.0\\nThought:\"\n","  ]\n","}\n","\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 18:llm:ChatOpenAI] [2.20s] Exiting LLM run with output:\n","\u001b[0m{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \"The final answer is 75.0\\nFinal Answer: 75.0\",\n","        \"generation_info\": {\n","          \"finish_reason\": \"stop\",\n","          \"logprobs\": null\n","        },\n","        \"type\": \"ChatGeneration\",\n","        \"message\": {\n","          \"lc\": 1,\n","          \"type\": \"constructor\",\n","          \"id\": [\n","            \"langchain\",\n","            \"schema\",\n","            \"messages\",\n","            \"AIMessage\"\n","          ],\n","          \"kwargs\": {\n","            \"content\": \"The final answer is 75.0\\nFinal Answer: 75.0\",\n","            \"additional_kwargs\": {}\n","          }\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": {\n","    \"token_usage\": {\n","      \"completion_tokens\": 16,\n","      \"prompt_tokens\": 227,\n","      \"total_tokens\": 243\n","    },\n","    \"model_name\": \"gpt-3.5-turbo-1106\",\n","    \"system_fingerprint\": \"fp_cbe4fa03fe\"\n","  },\n","  \"run\": null\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 19:parser:ReActSingleInputOutputParser] Entering Parser run with input:\n","\u001b[0m[inputs]\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence > 19:parser:ReActSingleInputOutputParser] [1ms] Exiting Parser run with output:\n","\u001b[0m{\n","  \"lc\": 1,\n","  \"type\": \"constructor\",\n","  \"id\": [\n","    \"langchain\",\n","    \"schema\",\n","    \"agent\",\n","    \"AgentFinish\"\n","  ],\n","  \"kwargs\": {\n","    \"return_values\": {\n","      \"output\": \"75.0\"\n","    },\n","    \"log\": \"The final answer is 75.0\\nFinal Answer: 75.0\"\n","  }\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 13:chain:RunnableSequence] [2.21s] Exiting Chain run with output:\n","\u001b[0m[outputs]\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [6.94s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"output\": \"75.0\"\n","}\n"]}]},{"cell_type":"markdown","source":["## wikipedia"],"metadata":{"id":"fraElxdNmwd3"}},{"cell_type":"code","source":["question = \"Tom M. Mitchell is an American computer scientist \\\n","and the Founders University Professor at Carnegie Mellon University (CMU)\\\n","what book did he write?\"\n","\n","result = agent_executor.invoke({'input':question})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DpFV0pNhk3SJ","executionInfo":{"status":"ok","timestamp":1704959211752,"user_tz":-540,"elapsed":11284,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"a01cc00a-e931-44f0-a032-781e5d04feda"},"execution_count":219,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI should use Wikipedia to find out what book Tom M. Mitchell wrote.\n","Action: Wikipedia\n","Action Input: Tom M. Mitchell\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[33;1m\u001b[1;3mPage: Tom M. Mitchell\n","Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former Chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past President of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.\n","\n","Page: Ensemble learning\n","Summary: In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.\n","Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.\u001b[0m\u001b[32;1m\u001b[1;3mI now know that Tom M. Mitchell wrote the textbook \"Machine Learning.\"\n","Final Answer: Machine Learning\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# Python Agent"],"metadata":{"id":"5F5h3pI5nkbI"}},{"cell_type":"code","source":["python_agent = create_python_agent(\n","    llm,\n","    tool=PythonREPLTool(),\n","    # 파이썬 에이전트에서도 이거 없으면 가끔 출력 파싱 에러남\n","    handle_parsing_errors=True,\n","    verbose=True\n",")"],"metadata":{"id":"06N4OtvWnKsk","executionInfo":{"status":"ok","timestamp":1704959291976,"user_tz":-540,"elapsed":2,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":229,"outputs":[]},{"cell_type":"code","source":["customer_list = [\n","    # first name, last name\n","    [\"Harrison\", \"Chase\"],\n","    [\"Lang\", \"Chain\"],\n","    [\"Dolly\", \"Too\"],\n","    [\"Elle\", \"Elem\"],\n","    [\"Geoff\",\"Fusion\"],\n","    [\"Trance\",\"Former\"],\n","    [\"Jen\",\"Ayai\"]\n","]"],"metadata":{"id":"O1TSgNd6nmuE","executionInfo":{"status":"ok","timestamp":1704959308888,"user_tz":-540,"elapsed":4,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":230,"outputs":[]},{"cell_type":"code","source":["result = python_agent.invoke({'input':f\"\"\"Sort these customers by last name and then first name and print the output: {customer_list}\"\"\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WAEeWbnMoDa-","executionInfo":{"status":"ok","timestamp":1704959316160,"user_tz":-540,"elapsed":7275,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"71f7b624-1ecc-4caa-de16-4d470187fd8e"},"execution_count":231,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI can use the sorted() function in Python to sort the list of customers by last name and then first name.\n","Action: Python_REPL\n","Action Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\n","sorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\n","print(sorted_customers)\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\n","\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mThe customers are now sorted by last name and then first name.\n","Final Answer: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}]},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-EX6vmaiqdK1","executionInfo":{"status":"ok","timestamp":1704959317267,"user_tz":-540,"elapsed":2,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"aee5a625-04b4-4d90-c1f4-799931d6c02d"},"execution_count":232,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input': \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\",\n"," 'output': \"[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\"}"]},"metadata":{},"execution_count":232}]},{"cell_type":"code","source":["eval(result['output'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fr-_GeqxqllF","executionInfo":{"status":"ok","timestamp":1704959318967,"user_tz":-540,"elapsed":3,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"059441de-7da8-40a9-b75d-81f119b9ca74"},"execution_count":233,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['Jen', 'Ayai'],\n"," ['Lang', 'Chain'],\n"," ['Harrison', 'Chase'],\n"," ['Elle', 'Elem'],\n"," ['Trance', 'Former'],\n"," ['Geoff', 'Fusion'],\n"," ['Dolly', 'Too']]"]},"metadata":{},"execution_count":233}]},{"cell_type":"markdown","source":["## 활용 예제\n","\n","\n","- ref: https://realpython.com/python-practice-problems/\n","\n","- A Caesar cipher is a simple substitution cipher in which each letter of the plain text is substituted with a letter found by moving n places down the alphabet. For example, assume the input plain text is the following:\n","`abcd xyz`\n","\n","- If the shift value, n, is 4, then the encrypted text would be the following:\n","`efgh bcd`\n","\n","- You are to write a function that accepts two arguments, a plain-text message and a number of letters to shift in the cipher. The function will return an encrypted string with all letters transformed and all punctuation and whitespace remaining unchanged.\n"],"metadata":{"id":"FFzyWLnACA-e"}},{"cell_type":"code","source":["input_text = 'dfq %^$^& mrpe'\n","\n","shift_num = 3\n","\n","def caesar_cipher(input_text: str, shift_num: int) -> str:\n","    #                0                        26\n","    alphabet = list('abcdefghijklmnopqrstuvwxyz')\n","    index = []\n","    for c in input_text:\n","        try:\n","            index.append(alphabet.index(c))\n","        except ValueError:\n","            index.append(c)\n","\n","    shifted = []\n","    for  i in index:\n","        if type(i) == int:\n","            shifted.append(alphabet[(i+shift_num) % 26])\n","        else:\n","            shifted.append(i)\n","\n","    return ''.join(shifted)\n","\n","caesar_cipher(input_text, shift_num)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"rVQE2IIFCUKK","executionInfo":{"status":"ok","timestamp":1704959321720,"user_tz":-540,"elapsed":5,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"c2269e12-357d-41ed-8eea-3671687e656c"},"execution_count":234,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'git %^$^& push'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":234}]},{"cell_type":"code","source":["# langchain.debug=True\n","\n","#프롬프트를 작성하고 에이전트에게 작업을 시켜보기\n","result = python_agent.invoke({'input':f\"\"\"\n","A Caesar cipher is a simple substitution cipher in which each letter of\n","the plain text is substituted with a letter found by moving n places down the alphabet.\n","\n","For example, assume the input plain text is the following:\n","\n","abcd xyz\n","\n","If the shift value, n, is 4, then the encrypted text would be the following:\n","\n","efgh bcd\n","\n","\n","Shift the string given in 'Input String' by the number given by 'Shift Value'.\n","The 'Input String' and 'Shift Value' are separated by ###.\n","\n","Input String: ###{input_text}###\n","Shift Value: ###{shift_num}###\n","\n","The input string is entered in lowercase letters of the alphabet and other characters.\n","Non-alphabetical characters are output without processing.\n","\"\"\"\n","})\n","\n","# langchain.debug=False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBBEoIkm_jDb","executionInfo":{"status":"ok","timestamp":1704959334860,"user_tz":-540,"elapsed":9853,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"09393bf8-2867-440d-ea94-a0c34ff2024e"},"execution_count":235,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI need to write a Python function to implement the Caesar cipher with the given shift value.\n","\n","Action: Python_REPL\n","Action Input:\n","```python\n","def caesar_cipher(input_string, shift):\n","    result = \"\"\n","    for char in input_string:\n","        if char.isalpha():\n","            shift_amount = shift % 26\n","            if char.islower():\n","                shifted_char = chr(((ord(char) - 97 + shift_amount) % 26) + 97)\n","            else:\n","                shifted_char = chr(((ord(char) - 65 + shift_amount) % 26) + 65)\n","            result += shifted_char\n","        else:\n","            result += char\n","    return result\n","\n","caesar_cipher(\"dfq %^$^& mrpe\", 3)\n","```\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n","Final Answer: gis %^$^& pusr\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}]},{"cell_type":"code","source":["result['output']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"NLyrodhU_jAq","executionInfo":{"status":"ok","timestamp":1704959338406,"user_tz":-540,"elapsed":408,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"967e8129-1e1c-4bc5-b8d5-822af46670f1"},"execution_count":236,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'gis %^$^& pusr'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":236}]},{"cell_type":"markdown","source":["# Define your own tool"],"metadata":{"id":"cFuUBXQJobSf"}},{"cell_type":"code","source":["from langchain.agents import tool\n","from datetime import date"],"metadata":{"id":"H5RXNYmZoIIL","executionInfo":{"status":"ok","timestamp":1704959342110,"user_tz":-540,"elapsed":4,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":237,"outputs":[]},{"cell_type":"code","source":["@tool\n","def time(text: str) -> str:\n","    \"\"\"\n","    Returns todays date, use this for any questions related to knowing todays date.\n","    The input should always be an empty string and this function will always return todays date.\n","    Any date mathmatics should occur outside this function.\n","    \"\"\"\n","    return str(date.today())"],"metadata":{"id":"UvurlVO7oeK7","executionInfo":{"status":"ok","timestamp":1704959342615,"user_tz":-540,"elapsed":2,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":238,"outputs":[]},{"cell_type":"code","source":["tools = tools+[time]\n","\n","agent = create_react_agent(llm, tools, prompt)\n","agent_executor = AgentExecutor(\n","    agent=agent, tools=tools,\n","    # True로 하면 Action이 없으면 Action이 없다는 메세지를 다시 LLM에 다시 넣고\n","    # Thought를 기반으로 Action을 찾아냄\n","    handle_parsing_errors=True,\n","    verbose=True\n",")"],"metadata":{"id":"86vm7NydofJ9","executionInfo":{"status":"ok","timestamp":1704959344582,"user_tz":-540,"elapsed":2,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":239,"outputs":[]},{"cell_type":"code","source":["result = agent_executor({\"input\":\"whats the date today?\"})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fycl5_R4p2BG","executionInfo":{"status":"ok","timestamp":1704959351878,"user_tz":-540,"elapsed":5506,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"3fea536c-0c09-4153-f37f-f6a06e1a3dc3"},"execution_count":240,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI should use the time function to get today's date.\n","Action: time\n","Action Input: \"\"\u001b[0m\u001b[38;5;200m\u001b[1;3m2024-01-11\u001b[0m\u001b[32;1m\u001b[1;3mI now know the date today.\n","Final Answer: The date today is January 11, 2024.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}]},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwGZMw_Mp3db","executionInfo":{"status":"ok","timestamp":1704959357793,"user_tz":-540,"elapsed":1128,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"d2f6db68-3713-4530-a7d1-4a831bbdbc8e"},"execution_count":241,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input': 'whats the date today?',\n"," 'output': 'The date today is January 11, 2024.'}"]},"metadata":{},"execution_count":241}]},{"cell_type":"markdown","source":["### 활용 예제\n","\n","- 스트링 쉬프트 함수를 툴로 만들기"],"metadata":{"id":"T5AiAIgGQdSq"}},{"cell_type":"code","source":["tools"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIPrm0IiY-hz","executionInfo":{"status":"ok","timestamp":1704959359822,"user_tz":-540,"elapsed":720,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"a631d4d3-717c-47a8-bdf9-faf9d5a7cbc2"},"execution_count":242,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7c03c7d4ed70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7c03c7d3f670>, model_name='gpt-3.5-turbo-1106', temperature=0.0, openai_api_key='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', openai_proxy='')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7c03c7d4ed70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7c03c7d3f670>, model_name='gpt-3.5-turbo-1106', temperature=0.0, openai_api_key='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', openai_proxy='')))>),\n"," WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n"," StructuredTool(name='time', description='time(text: str) -> str - Returns todays date, use this for any questions related to knowing todays date. \\n    The input should always be an empty string and this function will always return todays date.\\n    Any date mathmatics should occur outside this function.', args_schema=<class 'pydantic.main.timeSchemaSchema'>, func=<function time at 0x7c03c7dc30a0>)]"]},"metadata":{},"execution_count":242}]},{"cell_type":"code","source":["\n","# 함수의 디스크립션을 직접 적어보기\n","\n","@tool\n","def caesar_cipher(input_text: str, shift_num: int) -> str:\n","    \"\"\"\n","    Shift the given string by n places.\n","\n","    For example, assume the input plain text is the following:\n","    abcd xyz\n","\n","    If the shift value, n, is 4, then the encrypted text would be the following:\n","    efgh bcd\n","    \"\"\"\n","\n","    alphabet = list('abcdefghijklmnopqrstuvwxyz')\n","    index = []\n","    for c in input_text:\n","        try:\n","            index.append(alphabet.index(c))\n","        except ValueError:\n","            index.append(c)\n","\n","    shifted = []\n","    for  i in index:\n","        if type(i) == int:\n","            shifted.append(alphabet[(i+shift_num) % 26])\n","        else:\n","            shifted.append(i)\n","\n","    return ''.join(shifted)\n"],"metadata":{"id":"0izItBiS-6Kl","executionInfo":{"status":"ok","timestamp":1704959393078,"user_tz":-540,"elapsed":422,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":243,"outputs":[]},{"cell_type":"code","source":["# 툴에 추가\n","tools=tools+[caesar_cipher]\n","\n","tools"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2IZgpQZZCfw","executionInfo":{"status":"ok","timestamp":1704959410133,"user_tz":-540,"elapsed":3,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"b49e055b-ec97-44d1-900a-2074df0ce8c0"},"execution_count":244,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7c03c7d4ed70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7c03c7d3f670>, model_name='gpt-3.5-turbo-1106', temperature=0.0, openai_api_key='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', openai_proxy='')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7c03c7d4ed70>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7c03c7d3f670>, model_name='gpt-3.5-turbo-1106', temperature=0.0, openai_api_key='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', openai_proxy='')))>),\n"," WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n"," StructuredTool(name='time', description='time(text: str) -> str - Returns todays date, use this for any questions related to knowing todays date. \\n    The input should always be an empty string and this function will always return todays date.\\n    Any date mathmatics should occur outside this function.', args_schema=<class 'pydantic.main.timeSchemaSchema'>, func=<function time at 0x7c03c7dc30a0>),\n"," StructuredTool(name='caesar_cipher', description='caesar_cipher(input_text: str, shift_num: int) -> str - Shift the given string by n places.\\n    \\n    For example, assume the input plain text is the following:\\n    abcd xyz\\n\\n    If the shift value, n, is 4, then the encrypted text would be the following:\\n    efgh bcd', args_schema=<class 'pydantic.main.caesar_cipherSchemaSchema'>, func=<function caesar_cipher at 0x7c03c7dc1630>)]"]},"metadata":{},"execution_count":244}]},{"cell_type":"code","source":["# 구조화된 체팅 프롬프트\n","prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n","\n","prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bXeaqrfSf-iE","executionInfo":{"status":"ok","timestamp":1704959424275,"user_tz":-540,"elapsed":417,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"3ec4fed0-e9a2-41ce-9596-55fae962b8ee"},"execution_count":245,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatPromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'))])"]},"metadata":{},"execution_count":245}]},{"cell_type":"code","source":["# 에이전트 만들기\n","agent = create_structured_chat_agent(\n","    llm, tools, prompt\n",")\n","\n","# 에이전트 실행기\n","agent_executor = AgentExecutor(\n","    agent=agent, tools=tools,\n","    handle_parsing_errors=True,\n","    verbose=True\n",")"],"metadata":{"id":"Avc36N_XgCWM","executionInfo":{"status":"ok","timestamp":1704959445846,"user_tz":-540,"elapsed":449,"user":{"displayName":"조준우","userId":"07581913480846489655"}}},"execution_count":246,"outputs":[]},{"cell_type":"code","source":["# 실행!\n","result = agent_executor({\"input\":\"Shift the text 'dfq %^$^& mrpe' by 3\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GKIeRCD8eEym","executionInfo":{"status":"ok","timestamp":1704959457221,"user_tz":-540,"elapsed":8161,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"19ada606-e2e8-4bef-f01e-f9ec0c05d407"},"execution_count":247,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mAction:\n","```{\n","  \"action\": \"caesar_cipher\",\n","  \"action_input\": {\n","    \"input_text\": \"dfq %^$^& mrpe\",\n","    \"shift_num\": 3\n","  }\n","}```\u001b[0m\u001b[36;1m\u001b[1;3mgit %^$^& push\u001b[0m\u001b[32;1m\u001b[1;3m```\n","{\n","  \"action\": \"Final Answer\",\n","  \"action_input\": \"git %^$^& push\"\n","}\n","```\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}]},{"cell_type":"code","source":["result['output']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"WzGU70AxeJK4","executionInfo":{"status":"ok","timestamp":1704959460089,"user_tz":-540,"elapsed":431,"user":{"displayName":"조준우","userId":"07581913480846489655"}},"outputId":"fafe4bcf-d5a2-429d-98a9-237ba950ae01"},"execution_count":248,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'git %^$^& push'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":248}]},{"cell_type":"code","source":[],"metadata":{"id":"EbfcaXd5byaN"},"execution_count":null,"outputs":[]}]}